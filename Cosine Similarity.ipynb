{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "import time\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Resume Dataset\n",
    "# Set Folder Path\n",
    "folder = 'D:\\\\GWU\\\\Spring 2019\\\\DATS 6202\\\\Dataset\\\\resume_part1\\\\'\n",
    "# Use glob to list all the txt files\n",
    "files = [f for f in glob.glob(folder + \"**/*.txt\", recursive=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data Scientist Resumes 18467\n",
      "Total Washington, DC Resumes 214950\n",
      "DC Data Scientist Resumes 1298\n",
      "DC Database Administrator Resumes 5503\n",
      "DC Financial Analyst Resumes 21058\n",
      "DC IT Manager 19181\n",
      "DC Computer Systems Analyst 3048\n",
      "DC Computer Systems Administrator 2171\n",
      "All Database Administrator Resumes 53613\n",
      "All Computer Systems Administrator 20550\n",
      "All IT Manager 257602\n"
     ]
    }
   ],
   "source": [
    "# List of all the txt files for corresponding positions\n",
    "files_ds=[files[x] for x in range(len(files)) if files[x].rsplit('\\\\',2)[1].rsplit('_',1)[0]=='Data Scientist']\n",
    "print(\"All Data Scientist Resumes\",len(files_ds))\n",
    "\n",
    "files_DC=[files[x] for x in range(len(files)) if files[x].rsplit('\\\\',2)[1].rsplit('_',1)[1] == 'Washington, DC']\n",
    "print(\"Total Washington, DC Resumes\",len(files_DC))\n",
    "\n",
    "files_DC_ds=[files_DC[x] for x in range(len(files_DC)) if files_DC[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'Data Scientist']\n",
    "print(\"DC Data Scientist Resumes\",len(files_DC_ds))\n",
    "\n",
    "files_DC_da=[files_DC[x] for x in range(len(files_DC)) if files_DC[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'Database Administrator']\n",
    "print(\"DC Database Administrator Resumes\",len(files_DC_da))\n",
    "\n",
    "files_DC_fa=[files_DC[x] for x in range(len(files_DC)) if files_DC[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'Financial Analyst']\n",
    "print(\"DC Financial Analyst Resumes\",len(files_DC_fa))\n",
    "\n",
    "files_DC_itm=[files_DC[x] for x in range(len(files_DC)) if files_DC[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'IT Manager']\n",
    "print(\"DC IT Manager\",len(files_DC_itm))\n",
    "\n",
    "files_DC_csa=[files_DC[x] for x in range(len(files_DC)) if files_DC[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'Computer Systems Analyst']\n",
    "print(\"DC Computer Systems Analyst\",len(files_DC_csa))\n",
    "\n",
    "files_DC_csad=[files_DC[x] for x in range(len(files_DC)) if files_DC[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'Computer Systems Administrator']\n",
    "print(\"DC Computer Systems Administrator\",len(files_DC_csad))\n",
    "\n",
    "files_da=[files[x] for x in range(len(files)) if files[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'Database Administrator']\n",
    "print(\"All Database Administrator Resumes\",len(files_da))\n",
    "\n",
    "files_csad=[files[x] for x in range(len(files)) if files[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'Computer Systems Administrator']\n",
    "print(\"All Computer Systems Administrator\",len(files_csad))\n",
    "\n",
    "files_im=[files[x] for x in range(len(files)) if files[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] == 'IT Manager']\n",
    "print(\"All IT Manager\",len(files_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accountant                        586003\n",
      "Marketing Manager                 418090\n",
      "Financial Manager                 400268\n",
      "Financial Analyst                 341882\n",
      "Management Analyst                281921\n",
      "IT Manager                        257602\n",
      "Business Operations Manager       186300\n",
      "Construction Manager              160471\n",
      "Loan Officer                      146084\n",
      "Laboratory Technician             116424\n",
      "Financial Advisor                 101380\n",
      "Interpreter                        96441\n",
      "HR Specialist                      91969\n",
      "High School Teacher                60590\n",
      "Compliance Officer                 56259\n",
      "Database Administrator             53613\n",
      "Computer Support Specialist        38760\n",
      "Civil Engineer                     27964\n",
      "Fundraiser                         26972\n",
      "Computer Systems Analyst           26736\n",
      "Information Security Analyst       22968\n",
      "Computer Systems Administrator     20550\n",
      "Data Scientist                     18467\n",
      "Lawyer                             14032\n",
      "Cost Estimator                      6567\n",
      "Actuary                             2553\n",
      "Cartographer                        2011\n",
      "Computer Network Architect          1280\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract and print the Job Category from File Name\n",
    "Category=pd.Series(files[x].rsplit('\\\\',2)[1].rsplit('_',1)[0] for x in range(len(files))).value_counts()\n",
    "print(Category)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DS resume table\n",
    "resumes=[]\n",
    "for filename in files_ds[0:]:\n",
    "    with open(filename,encoding=\"utf8\") as f:  \n",
    "        resume_dict = json.load(f)  ## data is a dictionary that contains the JSON info\n",
    "        resumes= resumes+ [resume_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the titles       \n",
    "titles=[]\n",
    "p=[]\n",
    "for i in range(len(resumes)):\n",
    "    if any ('experience_history' in s for s in list(resumes[i].keys())):\n",
    "        for j in resumes[i]['experience_history']:\n",
    "            if any ('title' in s for s in list(j.keys())):\n",
    "                titles.append(j['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all the titles to lowercase\n",
    "titles=[x.lower() for x in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique titles, where strip() is used to remove all the leading and trailing spaces from a string.\n",
    "uniquetitle = reduce(lambda l, x: l if x in l else l+[x.strip()], titles, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the unique title \n",
    "cleaned_title=[]\n",
    "for i in range(len(uniquetitle)):\n",
    "        cleaned_title.append(re.sub(r'\\(\\w+\\s?','',re.sub(r'\\w+\\)\\s?','',re.sub(r'\\s?\\([^)]*\\)\\s?', '', re.sub(r'\\s?\\\"[^)]*\\\"\\s?', '', uniquetitle[i].lower())))).replace(' & ',', ').replace(' & ',', ').replace('&',', ').replace(' / ',', ').replace('/ ',', ').replace('/',', ').replace(' and ',', ').replace(':',', ').replace(';',', ').replace('•',', ').replace('\"','').replace('.',', ').replace('ø','').replace('','').replace('-',', ').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat the list and remove empty set\n",
    "flat_list=[]\n",
    "flat_list = [item.strip() for sublist in cleaned_title for item in sublist]    \n",
    "while('' in flat_list) : \n",
    "    flat_list.remove('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Flat List\n",
    "flat_list_uni = reduce(lambda l, x: l if x in l else l+[x], flat_list, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngrams   \n",
    "def ngrams(string, n=3):\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Ngrams to Generate TF-IDF Matrix\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(flat_list_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    }
   ],
   "source": [
    "# Check the location for scientist\n",
    "for i in range(len(flat_list_uni)):\n",
    "    if flat_list_uni[i]=='scientist':\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5053)\t0.40092316243435583\n",
      "  (0, 1469)\t0.39989350433918536\n",
      "  (0, 2869)\t0.3912290470650775\n",
      "  (0, 2076)\t0.30426997984598536\n",
      "  (0, 4014)\t0.41031624629957697\n",
      "  (0, 5441)\t0.4108159672001371\n",
      "  (0, 3045)\t0.3107671704412755\n"
     ]
    }
   ],
   "source": [
    "# Print the TF-IDF matrix for scientist\n",
    "print(tf_idf_matrix[245])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "# Compressed Sparse Row (CSR) Matrix\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELFTIMED: 5.957417011260986\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the time used to compute CSR Matrix\n",
    "# It stores the top 100 most similar items, and only show items with similiarity above 0.85\n",
    "t1 = time.time()\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 100, 0.85)\n",
    "t = time.time()-t1\n",
    "print(\"SELFTIMED:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Matched dataframe, and calculated the similarity value\n",
    "def get_matches_df(sparse_matrix, name_vector, top=10000):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similairity': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_side</th>\n",
       "      <th>right_side</th>\n",
       "      <th>similairity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>systems programmer</td>\n",
       "      <td>senior systems programmer</td>\n",
       "      <td>0.863102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>programmer analyst</td>\n",
       "      <td>data programmer analyst</td>\n",
       "      <td>0.878023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>competitive intelligence</td>\n",
       "      <td>competitive intelligence analyst</td>\n",
       "      <td>0.923674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>of mathematics</td>\n",
       "      <td>0.886275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>product development</td>\n",
       "      <td>product development scientist</td>\n",
       "      <td>0.858567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>design engineer</td>\n",
       "      <td>data design engineer</td>\n",
       "      <td>0.876545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>senior machine learning</td>\n",
       "      <td>0.867457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>data reviewer</td>\n",
       "      <td>data review</td>\n",
       "      <td>0.854878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>business data analyst</td>\n",
       "      <td>business data analyst intern</td>\n",
       "      <td>0.868709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>quality control chemist</td>\n",
       "      <td>quality control senior chemist</td>\n",
       "      <td>0.852782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>software design engineer intern</td>\n",
       "      <td>software design engineer in test</td>\n",
       "      <td>0.856837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>graduate research assistant iii</td>\n",
       "      <td>graduate research assistant ii</td>\n",
       "      <td>0.962161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>clinical data manager</td>\n",
       "      <td>clinical data manager 2</td>\n",
       "      <td>0.875224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>computer operator</td>\n",
       "      <td>senior computer operator</td>\n",
       "      <td>0.859492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>oracle principle software engineer,</td>\n",
       "      <td>principle software engineer</td>\n",
       "      <td>0.872171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>senior project coordinator</td>\n",
       "      <td>project coordinator</td>\n",
       "      <td>0.867084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>business development intern</td>\n",
       "      <td>business development</td>\n",
       "      <td>0.887296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>data reviewer</td>\n",
       "      <td>data review</td>\n",
       "      <td>0.854878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>project scientist</td>\n",
       "      <td>data project scientist</td>\n",
       "      <td>0.853724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>acquisitions</td>\n",
       "      <td>data acquisition</td>\n",
       "      <td>0.866692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                left_side                        right_side  \\\n",
       "3688                   systems programmer         senior systems programmer   \n",
       "268                    programmer analyst           data programmer analyst   \n",
       "1996             competitive intelligence  competitive intelligence analyst   \n",
       "928                           mathematics                    of mathematics   \n",
       "3217                  product development     product development scientist   \n",
       "2596                      design engineer              data design engineer   \n",
       "1598                     machine learning           senior machine learning   \n",
       "3093                        data reviewer                       data review   \n",
       "3492                business data analyst      business data analyst intern   \n",
       "2644              quality control chemist    quality control senior chemist   \n",
       "1440      software design engineer intern  software design engineer in test   \n",
       "4570      graduate research assistant iii    graduate research assistant ii   \n",
       "457                 clinical data manager           clinical data manager 2   \n",
       "2411                    computer operator          senior computer operator   \n",
       "2915  oracle principle software engineer,       principle software engineer   \n",
       "2066           senior project coordinator               project coordinator   \n",
       "4076          business development intern              business development   \n",
       "3093                        data reviewer                       data review   \n",
       "1457                    project scientist            data project scientist   \n",
       "2501                         acquisitions                  data acquisition   \n",
       "\n",
       "      similairity  \n",
       "3688     0.863102  \n",
       "268      0.878023  \n",
       "1996     0.923674  \n",
       "928      0.886275  \n",
       "3217     0.858567  \n",
       "2596     0.876545  \n",
       "1598     0.867457  \n",
       "3093     0.854878  \n",
       "3492     0.868709  \n",
       "2644     0.852782  \n",
       "1440     0.856837  \n",
       "4570     0.962161  \n",
       "457      0.875224  \n",
       "2411     0.859492  \n",
       "2915     0.872171  \n",
       "2066     0.867084  \n",
       "4076     0.887296  \n",
       "3093     0.854878  \n",
       "1457     0.853724  \n",
       "2501     0.866692  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matched String Similarity   \n",
    "matches_df = get_matches_df(matches, flat_list_uni, top=5371)\n",
    "matches_df = matches_df[matches_df['similairity'] < 0.99999] # Remove all exact matches\n",
    "matches_df.sample(20,replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a csv file for macthed similarity\n",
    "matches_df.to_csv(path_or_buf='D:\\\\GWU\\\\Spring 2019\\\\DATS 6202\\\\Python\\\\Job & Resume\\\\matches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get title count\n",
    "counter=collections.Counter(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use count as frequency and Covert Count to Dict\n",
    "kk=pd.DataFrame()\n",
    "kk['Titles']=counter.keys()\n",
    "kk['Count']=counter.values()\n",
    "kk=kk.sort_values(by=['Count'], ascending=False)           \n",
    "kk_dict=kk.set_index('Titles').to_dict()['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the similarity value with left side and right side\n",
    "new_match = matches_df.replace(kk_dict) \n",
    "new_match['Difference']=new_match['left_side']-new_match['right_side']\n",
    "matches_df['left_side_value']=new_match['left_side']\n",
    "matches_df['right_side_value']=new_match['right_side']\n",
    "idx = (new_match['Difference'] <0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put most frenquent title on the left side and less frenquent title on the right side \n",
    "aa=matches_df\n",
    "aa.loc[idx,['left_side','right_side']] = aa.loc[idx,['right_side','left_side']].values\n",
    "aa.loc[idx,['left_side_value','right_side_value']] = aa.loc[idx,['right_side_value','left_side_value']].values\n",
    "aa['Difference']=aa['left_side_value']-aa['right_side_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch left and right side\n",
    "df_uniquetitle=pd.DataFrame({'right_side':flat_list_uni})\n",
    "df_uniquetitle = pd.merge(df_uniquetitle, aa, how='left',left_on='right_side',right_on='right_side')    \n",
    "df_uniquetitle=df_uniquetitle.sort_values(by=['left_side_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert the not na DF to Dict        \n",
    "df_uniquetitle_notna=df_uniquetitle.dropna()\n",
    "kkk_dict=df_uniquetitle_notna.set_index('right_side').to_dict()['left_side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dictionary to replace the previous flattened unique titles in order to narrowdown the unique titles\n",
    "df_uniquetitle_new=pd.DataFrame({'right_side':flat_list_uni})\n",
    "df_uniquetitle_new= df_uniquetitle_new.replace(kkk_dict) \n",
    "uniquetitle_new = reduce(lambda l, x: l if x in l else l+[x], df_uniquetitle_new['right_side'], [])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total new uniquetitles:  22285\n"
     ]
    }
   ],
   "source": [
    "print(\"Total new uniquetitles: \",len(uniquetitle_new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
